{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ID                               TITLE       GENRE  \\\n",
      "0   1       Oscar et la dame rose (2009)       drama    \n",
      "1   2                       Cupid (1997)    thriller    \n",
      "2   3   Young, Wild and Wonderful (1980)       adult    \n",
      "3   4              The Secret Sin (1915)       drama    \n",
      "4   5             The Unrecovered (2007)       drama    \n",
      "\n",
      "                                         DESCRIPTION  \n",
      "0   Listening in to a conversation between his do...  \n",
      "1   A brother and sister with a past incestuous r...  \n",
      "2   As the bus empties the students for their fie...  \n",
      "3   To help their unemployed father make ends mee...  \n",
      "4   The film's title refers not only to the un-re...  \n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('Genre Classification Dataset/train_data.txt', delimiter=':::', header=None, names=['ID', 'TITLE', 'GENRE', 'DESCRIPTION'], engine='python')\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and Labels\n",
    "X = data['DESCRIPTION']\n",
    "y = data['GENRE']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using TF-IDF\n",
    "tfidf = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Logistic Regression model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5231946878170248\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "      action        0.58      0.08      0.14       263\n",
      "       adult        0.88      0.06      0.12       112\n",
      "   adventure        0.29      0.03      0.05       139\n",
      "   animation        0.00      0.00      0.00       104\n",
      "   biography        0.00      0.00      0.00        61\n",
      "      comedy        0.51      0.44      0.47      1443\n",
      "       crime        0.00      0.00      0.00       107\n",
      " documentary        0.58      0.88      0.70      2659\n",
      "       drama        0.46      0.83      0.59      2697\n",
      "      family        1.00      0.01      0.01       150\n",
      "     fantasy        0.00      0.00      0.00        74\n",
      "   game-show        1.00      0.15      0.26        40\n",
      "     history        0.00      0.00      0.00        45\n",
      "      horror        0.73      0.36      0.48       431\n",
      "       music        0.77      0.12      0.20       144\n",
      "     musical        0.00      0.00      0.00        50\n",
      "     mystery        0.00      0.00      0.00        56\n",
      "        news        0.00      0.00      0.00        34\n",
      "  reality-tv        0.80      0.02      0.04       192\n",
      "     romance        0.00      0.00      0.00       151\n",
      "      sci-fi        0.86      0.04      0.08       143\n",
      "       short        0.60      0.10      0.18      1045\n",
      "       sport        0.73      0.09      0.15        93\n",
      "   talk-show        0.00      0.00      0.00        81\n",
      "    thriller        0.23      0.01      0.02       309\n",
      "         war        0.00      0.00      0.00        20\n",
      "     western        0.98      0.59      0.74       200\n",
      "\n",
      "     accuracy                           0.52     10843\n",
      "    macro avg       0.41      0.14      0.16     10843\n",
      " weighted avg       0.52      0.52      0.44     10843\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\hp\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
